{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db595e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Matec\n",
      "[nltk_data]     Pro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random \n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1532bea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MATECP~1\\AppData\\Local\\Temp/ipykernel_116352/3584188613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# defining some parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# the deep learning model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# defining some parameters\n",
    "input_shape = (len(train_X[0]),)\n",
    "output_shape = len(train_y[0])\n",
    "epochs = 200\n",
    "# the deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(output_shape, activation = \"softmax\"))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "model.fit(x=train_X, y=train_y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a82cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "User: saluy\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "ChatBot: please elaborate your question\n",
      "User: salut\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "ChatBot: Hi\n",
      "User: how are you\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "ChatBot: Thanks For Asking!How can I help you?\n",
      "User: comment vas tu\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "ChatBot: You can call me UIEchatbox.\n",
      "User: how are you\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ChatBot: Thanks For Asking!How can I help you?\n",
      "User: comment tu t'appelle\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ChatBot: tu peux m'appeler UIEchatbox\n",
      "User: merci\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "ChatBot: Can't Understand Your Question\n",
      "User: I want to know the various departments in this company\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ChatBot: The department are:Projects,IT,Production,OutSource\n",
      "User: "
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"C://Users//Matec Pro//Documents//intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67ef87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
